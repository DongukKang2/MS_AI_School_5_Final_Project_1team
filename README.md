# MS_AI_School_5_Final_Project_1team

- 🍽️ PT SAM - 개인 트레이너를 열다

## 📋 프로젝트 개요

- **프로젝트명**: PT SAM (Personal Trainer SAM)
- **기간** : 2024.01.20(월) ~ 2024.02.26(목)
- **팀장** : 홍용민
- **팀원** : 강동욱, 강찬영, 안승랑, 조약돌, 최연희, 최영주

##  🎥 프로젝트 시연 영상


## 💡 프로젝트 소개
* PT SAM은 AI 기술을 활용하여 사용자의 운동 자세를 실시간으로 분석하고 교정해주는 개인 트레이너 모바일 애플리케이션입니다. 
* 운동 초보자들의 부상 예방 및 올바른 자세 교정을 목표로 체계적인 운동 데이터 관리 및 맞춤형 피드백을 제공합니다.

### 주요 특징
- 실시간 운동 자세 분석 및 교정
- 사용자 맞춤형 운동 루틴 추천
- AI 챗봇을 통한 운동 관련 질문 해결
- 체계적인 운동 데이터 관리
- 음성 인식을 통한 편리한 인터페이스

## 🎯 개발 목표
### 1. 개발 배경
- 디지털 헬스케어 시장의 지속적인 성장(2027년 509B 예상)
- 운동 초보자의 부상 예방 및 올바른 자세 교정 필요성
- 체계적인 운동 데이터 관리 필요성 증대
- AI 기술을 활용한 접근성 높은 개인 트레이너 서비스 구현

### 2. 타겟 사용자
- 운동 초보자 및 올바른 자세를 배우고자 하는 사용자
- 개인 트레이너 없이 효과적인 운동을 원하는 사용자
- 체계적인 운동 기록 관리가 필요한 사용자

## 🔍 주요 기능

1. **운동 자세 실시간 분석 및 교정**
- Custom Vision을 통해 정상/비정상 자세 판별 & 영상 프레임 단위로 분할할
- MediaPipe를 활용한 32개 관절 좌표 추출
- 올바른 운동자세 판단 및 자세 교정 피드백 제공

2. **체계적인 운동 데이터 축적**
- 운동 횟수, 정확도 등을 바탕으로 운동 기록 저장 및 분석
- AI 기반 챗봇 서비를 통한 맞춤형 운동 추천

3. **AI 기반 챗봇 서비스**
- 운동 중 궁금한 점을 AI 챗봇을 통해 즉시 해결
- 사용자의 운동 패턴 분석을 통한 맞춤형 운동 루틴 추천

4. **음성 인식(STT) 인터페이스**
- 사용자의 음성 입력을 텍스트로 변환
- 음성 명령으로 운동 관련 질문 처리

## 🛠 기술 스택
### Frontend
- Flutter
- Figma (UI/UX 디자인)

### Backend
- Python
- Flask
- Azure Cloud (App Service)

### AI/ML
- Azure Custom Vision
- Google MediaPipe
- OpenAI GPT-4o
- Azure Speech-to-Text
- LlamaIndex (RAG 시스템)

### Development Tools
- VSCode
- Git

## 👥 팀원 및 역할
| 이름 | 역할 |
|------|------|
| 강동욱 | - Custom Vision & YOLOv11 모델 개발<br>- LLM 모델 개발(오픈소스, GPT-4o 기반 RAG)<br>- 시스템 연동 및 테스트  |
| 강찬영 | - Custom Vision 모델 개발<br>- OpenAI 모델 개발<br>- 음성 인식(STT) |
| 안승랑 | - UI/UX 디자인<br>- 프론트엔드<br>- 시스템 연동 및 테스트 |
| 조약돌 | - DB 설계 및 관리<br>- 백엔드 |
| 최연희 | - UI/UX 디자인<br>- 프론트엔드<br>- 시연 영상<br>- - Figma 활용 UI/UX 디자인 |
| 최영주 | - Google MediaPipe 모델 개발<br>- PPT|
| 홍용민 | - PM / Google MediaPipe 모델 개발<br>- PPT |


## 📅 개발 일정

- 2024.01.20: 데이터 수집 (AI Hub)
- 2024.02.01: UI/UX 설계 (Figma, Flutter, VSCode)
- 2024.02.14: 모델 개발 (CustomVision, Google Mediapipe)
- 2024.02.20: 기능 연결 및 서비스 구축 (BE&FE 연결 / OPEN AI)
- 2024.02.25: PPT 작성 및 발표 준비

## 🌟 Vision 모델
- 프로젝트에서는 다양한 비전 모델을 비교 분석하여 최적의 솔루션을 선택했습니다:

### Azure Custom Vision

- 다양한 운동 자세 인식에 90-95% 정확도 제공
-API 통합에 용이하여 개인화 자세 분석 모델 구축에 적합

### MediaPipe
- 모바일 환경에서도 초당 30프레임 이상 실시간 처리 가능
- 32개의 키 포인트로 자세 탐지
- 별도 서버 없이 즉각적인 피드백 제공으로 모바일 환경에 최적화

### YOLOv11
- 복잡한 자세와 세밀한 관절 움직임 탐지에 우수한 정확도 제공
- 실시간 분석에서는 실행이 어려움
- 서버 기반 솔루션에 적합한 모델

### 🤖 LLM 모델
- 사용자에게 개인화된 운동 피드백을 제공하기 위해 다음 LLM 모델을 활용했습니다:
### GPT-4o
- 고성능 상업용 API
- 편리한 통합 및 사용
- 뛰어난 추론 및 문제 해결 능력
- RAG 작업 결과 전문적이고 구체적인 내용 출력

### Qwen2.5-7B
- 오픈 소스 모델 (한국어 LLM 리더보드 27위)
- 데이터 보안 통제
- 완전한 커스터마이징 가능

## 📞 문의하기
- 이메일: example@gmail.com
- GitHub Issues: 버그 리포트 및 기능 제안

---
작성 날짜: 2024.03.01
마지막 업데이트: 2024.03.01
